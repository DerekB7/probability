{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "import numpy as np\n",
    "from fractions import Fraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is part of chapter 3 exercise 15 in Ross & Pekoz, which is a very nice exercise...  \n",
    "\n",
    "suppose we have \n",
    "$Y_i$ which takes on values (for simplicity, only finitely many values)   \n",
    "\n",
    "$0$ with probability $p_0$, \n",
    "$1$ with probability $p_1$\n",
    "$\\vdots$\n",
    "$n$ with probability $p_n$\n",
    "\n",
    "$1 \\lt m = \\bar{Y} = p_0 \\cdot 0 + p_1 \\cdot 1 + ... + p_n \\cdot n$  \n",
    "\n",
    "The branching process identity, where $X_0 = 1$ and hence $X_1 = \\sum_{i=1}^{X_0} Y_i^{(1)} = \\sum_{i=1}^{1} Y_i^{(1)} = Y_1^{(1)}$   \n",
    "\n",
    "note that each $Y_i^{(j)}$  is iid.  \n",
    "\n",
    "is that for $1 \\lt m$ we have $\\pi \\in (0,1)$ which is ultimate probability of extinction.  This then gives us an identity of \n",
    "\n",
    "\n",
    "$\\pi = p_0 \\pi^{0} + p_1 \\pi^{1} + ... + p_n \\pi^{n}  = E\\big[\\pi^Y\\big]$  \n",
    "\n",
    "- - - - - \n",
    "It is worth pointing out that $\\pi = 1$ will always satisfy this relation, i.e. because $\\pi := 1$ gives us \n",
    "\n",
    "$1 = \\pi = p_0 \\pi^{0} + p_1 \\pi^{1} + ... + p_n \\pi^{n} = p_0 \\cdot 1 + p_1 \\cdot 1 + ... + p_n \\cdot 1 = p_0 + p_1  + ... + p_n=1 $  \n",
    "\n",
    "however for $1 \\lt m$, and supposing our random variable $Y$ takes on at least two different values each with posive probability  (so it is not deterministic), and one of them is $p_0 \\gt 0$ (otherwise it has zero probability of going extinct), then we know $0 \\lt p_0 \\lt \\pi$, so for any $\\pi \\in (0,1]$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note on convexity: So for some $\\pi \\in (0,1)$ we have \n",
    "\n",
    "$h_{\\pi}''(x) = \\frac{d^2}{dx^2}\\pi^x = \\pi^x \\big(\\log(\\pi)\\big)^2 \\gt 0$  \n",
    "\n",
    "which confirms strict convexity of $h$.  (Note that the second derviative *is* zero when $\\pi =1$ though.) Hence by Jensen's Inequality, we have \n",
    "\n",
    "$ \\pi^{E[Y]}  = h_{\\pi}\\Big(E\\big[Y\\big]\\Big)\\lt E\\Big[h_{\\pi}\\big(Y\\big)\\Big]=E\\big[\\pi^Y\\big] $  \n",
    "\n",
    "and we may use this strictness to prove claims about extinction probabilities.  \n",
    "\n",
    "First, with respect to extinction probabilities, we have 3 cases to consider, again supposing there exists some $\\pi \\in (0,1)$  \n",
    "\n",
    "**1.)** $m \\lt 1$  \n",
    "\n",
    "i.) $1 \\gt m  \\to  c \\lt m\\cdot c $  \n",
    "for $c \\lt 0$  \n",
    "making use of natural log, setting $c := \\log(\\pi)$  \n",
    "\n",
    "$\\log(\\pi) \\lt m \\log(\\pi)$  \n",
    "\n",
    "which is equivalent, via exponentiation to \n",
    "$\\pi \\lt \\pi^m $  \n",
    "\n",
    "ii.) by strict convexity, we have \n",
    "\n",
    "$\\pi^m = \\pi^{E[Y]} \\lt E\\big[\\pi^Y\\big]$ \n",
    "\n",
    "iii.) putting this altogether, if a viable $\\pi \\in (0,1)$ exists such that $E\\big[\\pi^Y\\big] =\\pi$, then we have \n",
    "\n",
    "$\\pi \\lt \\pi^m = \\pi^{E[Y]} \\lt E\\big[\\pi^Y\\big] = \\pi$ \n",
    "\n",
    "which is a contradiction, hence $\\pi = 1$ is the only solution in this case \n",
    "\n",
    "**2.)** $m = 1$  \n",
    "we have \n",
    "$\\pi = \\pi^m $  \n",
    "\n",
    "but by strict convexity for $\\pi \\in(0,1)$ we still have  \n",
    "\n",
    "$\\pi^m = \\pi^{E[Y]} \\lt E\\big[\\pi^Y\\big]$  \n",
    "\n",
    "and putting this together, we get \n",
    "\n",
    "$\\pi = \\pi^m = \\pi^{E[Y]} \\lt E\\big[\\pi^Y\\big] = \\pi$  \n",
    "\n",
    "which is a contradiction, hence $\\pi = 1$ is the only solution in this case \n",
    "\n",
    "\n",
    "**3.)** $m\\gt 1$  \n",
    "tells us the \n",
    "\n",
    "$\\pi^m \\lt \\pi$, which gives us  \n",
    "\n",
    "$\\pi^m = \\pi^{E[Y]} \\lt E\\big[\\pi^Y\\big] = \\pi$  \n",
    "\n",
    "which *is* valid.  Now we proceed to show that a root $\\pi \\in (0,1)$ must exist *and is in fact the solution*.  \n",
    "\n",
    "**approach 1: **  \n",
    "define \n",
    "\n",
    "$g(\\pi):= E\\big[\\pi^Y\\big] - \\pi$  \n",
    "\n",
    "the argument is easiest if $g$ is a polynomial (i.e. finitely many terms)-- with some insight, we may be able to apply a truncation argument to the countably infinite case.  However, we'll proceed for the general countably infinite case. \n",
    "\n",
    "Note that \n",
    "$g(0) = p_0 \\gt 0$ and $g(1) = 0$  \n",
    "\n",
    "now we restrict the domain to $\\pi \\in (0,1)$  and see \n",
    "\n",
    "$\\frac{d}{d \\pi} g(\\pi) = g'(\\pi) = \\big(\\sum_{k\\geq 1} k \\cdot p_k \\pi^{k-1}\\big) - 1$  \n",
    "\n",
    "$\\lim_{\\pi \\to 0^{+}}g'(\\pi) = -1$  \n",
    "$\\lim_{\\pi \\to 1^{-1}}g'(\\pi) = m - 1 \\gt 0$  \n",
    "\n",
    "equivalently, for sufficiently small $\\delta \\gt 0$ we have \n",
    "\n",
    "$g(\\delta) \\approx -1$  \n",
    "$g(1- \\delta) \\approx m - 1 \\gt 0$\n",
    "\n",
    "- - - - \n",
    "*technical note:*  \n",
    "in general $g(1)$ is not continuous -- if there is an infinite series, the series converges absolutely on the left and will explode to $\\infty$ on the right, hence this necsessitates more awkward concepts like formally differentiating at that point, or taking the limit from the left.  \n",
    "\n",
    "An alternative approach would be to note that $g'(\\pi) = m - 1 $ by construction, hence we can work backwards from here.  The mean exists and aside from the constant all terms are real non-negative.  This implies that we may sum only finitely many terms (r of them) to get $\\big(\\sum_{k=1}^r  k \\cdot p_k \\pi^{k-1}\\big) - 1 = (1-\\epsilon)m - 1$  by selecting large enough $r$.  For sufficiently small $\\epsilon$ we have $(1-\\epsilon)m - 1 \\gt 0$, which is achievable with large enough $r$.  We can run the underlying argument on a polynomial $h$ now of degree $r+1$ and have the same value at $h(0) = p_0$ and $h(1) \\lt 0$.  However the polynomial still has a continuously positve second derivative and thus a global minimum that is negative, and by basic continuity with polynomials (intermediate value theorem) $h(\\pi_h) = 0$ exists as a root to the truncated series.  This idea can be flushed out in a bit more detail.  The advantage of the truncated / polynomial approach is we have continuity in $(-\\infty, \\infty)$ for $h$ and $h'$ which easily allows us to state that there exists some delta such that  \n",
    "\n",
    "$h'(1-\\delta) \\gt 0$  \n",
    "\n",
    "but given monotonicity (all terms positive except constant), we have \n",
    "$g'(1-\\delta) \\gt h'(1-\\delta) \\gt 0$  \n",
    "\n",
    "hence $g$ has positive derivative near $1$ and negative derivative near $0$.  (Given convexity, it in fact must be negative, or else $0 \\lt p_0 = g(0) \\geq g(1) = 0$  which is impossible.)  But this implies that $g$ takes a minimum at some value $\\lt 1$ and hence its minimum is $\\lt 0$ which means that it has some root $0 \\lt \\pi \\lt 1$.  \n",
    "\n",
    "It's a bit of a detour, but in general polynomials are quite nice to work with, so a truncation argument of some kind can be rather useful.  \n",
    "\n",
    "In effect this analysis gets at the existence of 1 or 2 roots for an Ordinary Generating Function.  With some care we can modify the analysis to cover Moment Generating Functions.  \n",
    "\n",
    "- - - - \n",
    "\n",
    "further \n",
    "\n",
    "$g''(\\pi) = \\big(\\sum_{k\\geq 2} k^2 \\cdot p_k \\pi^{k-2}\\big) \\gt 0$  \n",
    "\n",
    "(note that every term in this series is positive, and the series is bounded above by a (finite) scalar multile of the second moment for the geometric distribution and hence the series is finite)  \n",
    "\n",
    "thus for $\\pi \\in(0,1)$ we have a strictly convex function.  While we could go directly perhaps to Rolle's Theorem here, notice by Intermediate Value Theorem that $g'$ changes sign in our domain and hence there is a zero, which must be a local minimum for $g$.  If that local minimum is not negative, then we could draw a flat line at that point that is a strict linear lower bound on $g$ (via strict convexity) which would contradict $g(1) = 0$\n",
    "\n",
    "because it would imply $0 \\lt g(1- \\delta)$ and we know $g(1- \\delta) \\lt g(1)$ by the positive derivative at $g(1- \\delta)$ (which itsel is a useful linear lower bound)  \n",
    "\n",
    "Hence that minimum must be negative, i.e. there exists $\\pi_{min} \\in (0,1)$ such that $g(\\pi_{min}) \\lt 0$, but again by intermediate value theorem, we know there must be some \n",
    "\n",
    "$\\pi^* \\in (0, \\pi_{min})$  \n",
    "$g(\\pi) = 0$  \n",
    "\n",
    "The fact that $g$ is convex for $\\pi \\in (0,1)$ and crosses the origin at $\\pi^*$ and $1$ in fact tells us that these are the only two roots in $[0,1]$ for $g$ --i.e. select some small $\\delta \\gt 0$ and evaluate the linear lower bounds at $g(\\delta)$ and $g(1- \\delta)$  \n",
    "\n",
    "- - - - \n",
    "We now know that there are two roots in $(0,1]$ given by $\\pi^*$ and $1$.  Why should we choose $\\pi^*$?  It is a bit of a detour, but a useful one: consider the result below titled \"Transient States -- Minimal Valued Solution\"  \n",
    "\n",
    "That is we've found the minimal $\\mathbf x$ where \n",
    "\n",
    "$\\mathbf {Px} = \\mathbf x$ \n",
    "\n",
    "and it is given by \n",
    "\n",
    "$\\mathbf {x} = \n",
    "\\begin{bmatrix}\n",
    "1\\\\ \n",
    "\\pi^1\\\\ \n",
    "\\pi^2\\\\\n",
    "\\pi^3\\\\\n",
    "\\vdots\n",
    "\\end{bmatrix}$  \n",
    "\n",
    "(which of course looks awfully similar to exponential tilting discussed in Feller chp 15 notes)  \n",
    "\n",
    "We can model the Branching Process (see pages 310, 311 of Gallagher for extra detail), as a countable state markov chain, whereby state $j=0$ is the absorbing state with extinction, state $1$ is state with one organism, state $2$ is state with two organisms, and so on.  Hence \n",
    "\n",
    "$P_{i,0}^n$ is the probability of extinction after $n$ iterations, given a start at state $i$.  \n",
    "\n",
    "The writeup below assures us that of all $P_{i,0}^n$ tends to a limit and that is given by the minimal solution, hence we have \n",
    "\n",
    "$\\lim_{n\\to \\infty} P_{i,1}^n =  P_{i,1}^\\infty = \\pi = \\big(\\pi^*\\big) \\lt 1$  \n",
    "\n",
    "and because these branching processes are independent we know that in general for $i\\geq 1$ we have \n",
    "\n",
    "$\\lim_{n\\to \\infty} P_{i,1}^n =  P_{i,1}^\\infty = \\pi^i = \\big(\\pi^*\\big)^i \\lt 1$  \n",
    "\n",
    "*remark: once again it is quite surprising just how much information we can glean from 'merely' knowing the mean of something like a branching process*  \n",
    "\n",
    "- - - - - \n",
    "**approach 2: **  \n",
    "When we consider, for $m \\gt 1$ \n",
    "\n",
    "$Z_n = \\frac{X_n}{m^n}$ \n",
    "\n",
    "which is non-negative Martingale and \n",
    "\n",
    "$\\lim_{n \\to \\infty} Z_n = \\lim_{n \\to \\infty}\\frac{X_n}{m^n}$   \n",
    "\n",
    "exists WP1 and is finite (ref e.g. page 108 of Ross and Pekoz). Hence for $m \\gt 1$ this **should** imply that a set with positive probability exists associated with the non-exintinction of the process.  However, it is not immediately clear to your author as to why this doesn't imply that $Z_n$ tends to zero....  (From research else where, the existence of a second moment for $X$ or even an in between $n\\log n$  \"moment\" would be enough to ensure some non-negative limitting portion in this martingale... unfortunately it seems to take considerable amount of machinery to derive and prove this nice result.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15. ** in Ross & Pekoz\n",
    "\n",
    "consider a Branching Process that starts with a single organism.  Let $\\pi$ denote the probability taht this organism eventually dies out.  Where $X_n$ is the number of individuals in generation $n$, show that $\\pi^{X_n}$, $n\\geq 0$ is a martingale.  \n",
    "\n",
    "$X_0 = 1$  \n",
    "$X_1 = Y^{(0)}_1$  \n",
    "$X_2 = \\sum_{k=1}^{X_1} Y^{(1)}_k$   \n",
    "$X_n = \\sum_{k=1}^{X_{n-1}} Y^{(n-1)}_k$   \n",
    "\n",
    "the $Y's$ are $iid$ with finite mean $m$.  We assume that probability of a given $Y\\gt 0$ to avoid trivialities.  \n",
    "\n",
    "From the above analysis we know that if $m\\leq $ then this process dies out WP1.  Equivalently, there is only one fixed  point in $[0,1]$  \n",
    "\n",
    "$\\pi = p_0 \\pi^{0} + p_1 \\pi^{1} + p_2\\pi^{2} + ...   = E\\big[\\pi^Y\\big]$  \n",
    "and that is at $1$  \n",
    "\n",
    "and when $m \\gt 1$ we know there are two fixed points  in \n",
    "$\\pi = p_0 \\pi^{0} + p_1 \\pi^{1} + p_2\\pi^{2} + ...   = E\\big[\\pi^Y\\big]$  \n",
    " \n",
    "- - - - \n",
    "so we assign \n",
    "\n",
    "$Z_n := \\pi^{X_n}$  \n",
    "\n",
    "first note that $0 \\leq Z_n  \\leq 1$  for $\\pi \\in [0,1]$ and hence this martingale is non-negative and bounded.  (We will make extra use of boundedness via bounded convergence theorem at the end.)  \n",
    "\n",
    "In particular, consider the case of $\\pi \\in (0,1)$  for $m \\gt 1$.  This gives us  \n",
    "\n",
    "$E\\Big[Z_n \\big \\vert Z_{n-1}, Z_{n-2}, ..., Z_1,Z_0\\Big] $   \n",
    "$ = E\\Big[\\pi^{X_n} \\big \\vert Z_{n-1}, Z_{n-2}, ..., Z_1,Z_0\\Big]$   \n",
    "$ = E\\Big[\\pi^{\\sum_{k=1}^{X_{n-1}} Y^{(n-1)}_k} \\big \\vert Z_{n-1}, Z_{n-2}, ..., Z_1,Z_0\\Big]$   \n",
    "$ = E\\Big[\\prod_{k=1}^{X_{n-1}}\\pi^{Y^{(n-1)}_k} \\big \\vert Z_{n-1}, Z_{n-2}, ..., Z_1,Z_0\\Big]$   \n",
    "$ = E\\Big[\\prod_{k=1}^{X_{n-1}}\\pi^{Y^{(n-1)}_k} \\Big]$   \n",
    "$= \\prod_{k=1}^{X_{n-1}} E\\Big[\\pi^{Y^{(n-1)}_k} \\Big]$  \n",
    "$= E\\big[\\pi^{Y} \\big]^{X_{n-1}}$  \n",
    "$= \\pi^{X_{n-1}}$  \n",
    "$=Z_{n-1}$  \n",
    "\n",
    "and hence this is a Martingale.  \n",
    "\n",
    "- - - - \n",
    "note again that for $\\pi \\in (0,1)$  for any given sample path, we have \n",
    "$ = E\\Big[\\prod_{k=1}^{X_{n-1}}\\pi^{Y^{(n-1)}_k} \\big \\vert z_{n-1}, Z_{n-2}= z_{n-2} ,..., Z_1= z_1 ,Z_0= \\pi\\Big]$   \n",
    "$= E\\Big[\\prod_{k=1}^{x_{n-1}}\\pi^{Y^{(n-1)}_k} \\big \\vert z_{n-1}, Z_{n-2}= z_{n-2} ,..., Z_1= z_1 ,Z_0= \\pi\\Big]$   \n",
    "$ = E\\Big[\\prod_{k=1}^{x_{n-1}}\\pi^{Y^{(n-1)}_k} \\Big]$   \n",
    "\n",
    "also by independence we have \n",
    "$ \\prod_{k=1}^{X_{n-1}} E\\Big[\\pi^{Y^{(n-1)}_k} \\Big]$  \n",
    "$= E\\big[\\pi^{Y} \\big]^{X_{n-1}}$  \n",
    "\n",
    "and because we choose $\\pi$ to be a fixed point, the key result is that \n",
    "$= E\\big[\\pi^{Y} \\big] =  \\pi$  \n",
    "\n",
    "\n",
    "further note that in the case of $\\pi =1$ the result is trivially true because  \n",
    "$E\\Big[Z_n \\big \\vert Z_{n-1}, Z_{n-2}, ..., Z_1,Z_0\\Big]  = 1 = Z_{n-1}$  \n",
    "\n",
    "- - - - \n",
    "Since $Z_n$ is a martingale, we have \n",
    "\n",
    "$E\\big[Z_n\\big] = E\\big[Z_{n-1}] = E\\big[Z_1\\big] = E\\big[Z_0\\big] = \\pi$  \n",
    "\n",
    "And by non-negativity we have \n",
    "\n",
    "$E\\big[\\big\\vert Z_n\\big\\vert \\big] = E\\big[Z_n\\big] =\\pi \\leq 1 \\lt \\infty$   \n",
    "\n",
    "hence the martingale convergence theorem tells us that \n",
    "$\\lim_{n \\to \\infty} Z_n = Z_{\\infty}$ exists and is finite WP1.  At this point it become convenient to take advantage of non-negativity and used $\\infty$ as a formal symbol. \n",
    "\n",
    "Since $\\big \\vert Z_n\\big \\vert = Z_n \\leq 1$ for all $n$ we may apply bounded convergence theorem and see \n",
    "\n",
    "$E\\big[Z_{\\infty}\\big] = E\\big[\\lim_{n \\to \\infty} Z_n\\big]  = \\lim_{n \\to \\infty} E\\big[Z_n\\big] = \\pi$  \n",
    "\n",
    "which tells us that \n",
    "\n",
    "$ \\pi =E\\big[Z_{\\infty}\\big] = E\\big[\\pi^{X_\\infty}\\big] = Pr\\{X_\\infty = 0\\}\\cdot \\pi^0 + Pr\\{X_\\infty = 1\\}\\cdot \\pi^1 + Pr\\{X_\\infty = 2\\}\\cdot \\pi^2 + ... $  \n",
    "\n",
    "But we know $  Pr\\{X_\\infty = 0\\} = \\pi$ and $\\pi^0 = 1$ so this tells us  \n",
    "\n",
    "$\\pi = \\pi + Pr\\{X_\\infty = 1\\}\\cdot \\pi^1 + Pr\\{X_\\infty = 2\\}\\cdot \\pi^2 + ... $  \n",
    "\n",
    "$0 =  Pr\\{X_\\infty = 1\\}\\cdot \\pi^1 + Pr\\{X_\\infty = 2\\}\\cdot \\pi^2 + ... $  \n",
    "\n",
    "but for any natural number $n$, $0 \\lt \\pi^n$, hence every term in that series must be $0$ and \n",
    "\n",
    "$Pr\\{X_\\infty = 1\\}\\ = 1 - \\pi$ \n",
    "\n",
    "and of course $\\pi^\\infty = 0$  \n",
    "\n",
    "Equivalently, $Z_{\\infty}$ is in effect a Bernouli random variable with value $1$ for the probability of extinction and value $0$ for the probability of $X_n$ growing infinitely large.  \n",
    "\n",
    "**For the $m \\gt 1$ case this gives us additional insight as to why the minimal root is the correct one** \n",
    "Recall that for any $m$, $\\pi =1$ trivially is satisfied as a martingale, and  \n",
    "\n",
    "$1 = \\pi = \\Pr\\{X_\\infty = 0\\}\\cdot \\pi^0 + Pr\\{X_\\infty = 1\\}\\cdot \\pi^1 + Pr\\{X_\\infty = 2\\}\\cdot \\pi^2 + ... $  \n",
    "$ = \\big(\\Pr\\{X_\\infty = 0\\} + Pr\\{X_\\infty = 1\\} + Pr\\{X_\\infty = 2\\} + ... \\big)\\cdot 1 = 1$  \n",
    "if $X_{\\infty}$ is a bona fide random variable.  If It is defective, we'd amend the last line to say  \n",
    "\n",
    "$ = \\big(\\Pr\\{X_\\infty = \\infty\\} + \\Pr\\{X_\\infty = 0\\} + Pr\\{X_\\infty = 1\\} + Pr\\{X_\\infty = 2\\} + ... \\big) = 1$  \n",
    "\n",
    "Note that for $\\pi = 1$ we don't have any insight on the ultimate probability distribution of $X_{\\infty}$ -- it could go extinct WP1 which matches $\\pi = 1$ but it could also have *any* other extinction probability and indeed be defective and yet the above series still sums to one on both sides.  \n",
    "\n",
    "Now consider the other root, where we find \n",
    "\n",
    "$E\\big[Z_{\\infty}\\big]  = \\pi \\lt 1$  \n",
    "if we allow for $X_\\infty$ to be defective we may write out the LHS as \n",
    "\n",
    "$\\Pr\\{X_\\infty = \\infty\\}\\pi^\\infty + \\Pr\\{X_\\infty = 0\\}\\cdot\\pi^0 + Pr\\{X_\\infty = 1\\}\\cdot\\pi + Pr\\{X_\\infty = 2\\}\\cdot \\pi + ...  = \\pi \\lt 1 $  \n",
    "\n",
    "$\\Pr\\{\\text{Extinction}\\}=\\Pr\\{X_\\infty = 0\\}\\cdot 1 = \\Pr\\{X_\\infty = 0\\}\\cdot\\pi^0 \\leq  \\big(\\Pr\\{X_\\infty = 0\\}\\cdot0 + Pr\\{X_\\infty = 1\\}\\cdot\\pi + Pr\\{X_\\infty = 2\\}\\cdot\\pi + ... \\big) = \\pi \\lt 1 $  \n",
    "\n",
    "Assume for a contradiction that $\\pi \\in (0,1)$ as \"just some fixed point that we can ignore\", then this tells us that \n",
    "\n",
    "$1= \\Pr\\{\\text{Extinction}\\} \\leq \\pi \\lt 1$  \n",
    "\n",
    "which is a contradiction.  That is, the smaller root implies that $1$ cannot be the true extinction probability, whereas the root of 1 says any probability of extinction works (aka an indeterminate case). The key idea then is to prove there can never be a root in $(0,1)$ for $m\\leq 1$, which we did (again assuming $p_0 \\gt 0$ and hence those processes must become extinct WP1.  After further working through convexity, we found that there *must* be fixed point in $\\pi \\in(0,1)$ for the $m\\gt 1$ case and hence those processes go extinct with some probability less than one.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transient States -- Minimal Valued Solution** exercise **6.1** in Gallager\n",
    "\n",
    "This is my adaptation / expansion of exercise 6.1 in Gallagher.  It closely follows the offficial solution.  It is conceptually a simple but powerful idea.  However the inductive step takes some care. *Feller chp 15 has a better step through of transient states -- it would be prudent to try and explicitly map what is in Feller to the below*  \n",
    "\n",
    "consider a countable state markov chain (time homogenous as always).  \n",
    "\n",
    "suppose we find $\\mathbf x$ where each component $x_i \\in [0,1]$  that satisfies \n",
    "\n",
    "$x_i = P_{i,j} + \\sum_{k\\neq j} P_{i,k} x_k$  for all $i \\geq 0$   \n",
    "\n",
    "**claim:**  \n",
    "$F_{i,j}^{(n)} \\leq x_i$ for all $n$  \n",
    "\n",
    "First: notice that $F_{i,j}^{(n)}$ is the (CDF) probability of having ever transitioned from $i \\to j$ after $n$ iterations.  In effect $j$ can be thought of as an absorbing state.  \n",
    "\n",
    "Since $F_{i,j}^{(n)}$ is a probability, we know $0\\leq F_{i,j}^{(n)}  \\leq 1$  \n",
    "\n",
    "Second: notice that $\\mathbf x = \\mathbf 1$ will always work because we are working with a row stochastic matrix.  \n",
    "\n",
    "**proof:**   \n",
    "*Base Case: *  \n",
    "$F_{i,j}^{(1)} = P_{i,j} \\leq P_{i,j} + \\sum_{k\\neq j} P_{i,k} x_k = x_i$  \n",
    "\n",
    "because $ P_{i,k}, x_k \\geq 0$, and we confirm that this holds over all $i$   \n",
    "\n",
    "*interpretation*  \n",
    "$\\sum_{k\\neq j} P_{i,k} x_k = \\mathbf e_i^T \\mathbf P \\big(\\mathbf x - x_j \\mathbf e_j\\big)$  \n",
    "\n",
    "since $\\mathbf P$ is row stochastic, we can interpret this two different ways.  I.e. \n",
    "\n",
    "$P_{i,j} + \\Big(\\mathbf e_i^T \\mathbf P\\Big) \\big(\\mathbf x - x_j \\mathbf e_j\\big)$  \n",
    "\n",
    "The forward / probability transition take:  \n",
    "gives the probability of starting in state $i$ then immediately transitioning into $j$ + the (disjoint) probability of the events of starting in $i$ and then transitioning into some state not equal to $j$ (inclusive of self loops) and collecting a 'reward' of $x_k$ there.  What we will ultimately see / iterate to is that this reward, in the limit and minimal form, will be the probability of going from one of those transition states into $j$.  \n",
    "\n",
    "The backward /expectations take:  \n",
    "$P_{i,j} + \\mathbf e_i^T \\Big(\\mathbf P \\big(\\mathbf x - x_j \\mathbf e_j\\big)\\Big) = \\mathbf e_i^T \\mathbf P \\mathbf e_j + \\mathbf e_i^T \\Big(\\mathbf P \\big(\\mathbf x - x_j \\mathbf e_j\\big)\\Big) = \\mathbf e_i^T \\mathbf P \\mathbf x + \\mathbf e_i^T \\mathbf P (1-x_j)\\mathbf e_j $   \n",
    "\n",
    "This is merely looking at the expected value of reward $x_k$ from all states $\\neq j$ from one step out, and grabbing it for the $i$th row, plus we get the reward of $1$ for going to $j$ with probability $P_{i,j}$  \n",
    "\n",
    "**note that if we fix state $j$ such that it is in fact an absorbing state, we should be able to enforce $x_j = 1$ and thus have **\n",
    "\n",
    "$=\\mathbf e_i^T\\Big(\\mathbf P \\mathbf x\\Big) = \\mathbf e_i^T \\mathbf x$  \n",
    "\n",
    "which holds over all $i$, hence where $\\mathbf v$ is a vector showing probabilities of being absorbed into $j$ after one iteration, we have \n",
    "\n",
    "$\\mathbf v^{(1)} \\leq \\mathbf P \\mathbf x= \\mathbf x$  \n",
    "\n",
    "where the inequality holds component wise.  The idea, which the inductive step ultimately shows, with some care:  \n",
    "\n",
    "$\\mathbf v^{(2)} = \\mathbf P \\mathbf v^{(1)}$  \n",
    "\n",
    "now if we re-run our argument, we find \n",
    "\n",
    "$\\mathbf v^{(2)} \\leq  \\mathbf P \\mathbf x = \\mathbf x$ \n",
    "\n",
    "and we iterate on this until getting that \n",
    "\n",
    "$\\mathbf v^{(n)} \\leq  \\mathbf P \\mathbf x = \\mathbf x$ \n",
    "\n",
    "in general we have \n",
    "\n",
    "which means we cannot directly multiply our way to the result. However it gives us monotonicity so we have \n",
    "\n",
    "$\\mathbf v^{(1)}\\leq \\mathbf v^{(2)}\\leq ... \\leq \\mathbf v^{(n-1)}\\leq \\mathbf v^{(n)}\\leq  \\mathbf P \\mathbf x = \\mathbf x$   \n",
    "\n",
    "and hence the limmiting probability of being absorbed in state $j$ is give by minimal $\\mathbf x$ that satisfies \n",
    "$x_i = P_{i,j} + \\sum_{k\\neq j} P_{i,k} x_k$  for all $i \\geq 0$   \n",
    "\n",
    "*Inductive Case: *  \n",
    "assume true for $n-1$, i.e. by inductive hypothesis, we have \n",
    "\n",
    "$F_{i,j}^{(n-1)} \\leq x_i$  \n",
    "\n",
    "we need to show this hold for $n \\geq 2$  \n",
    "\n",
    "$F_{i,j}^{(n)} =  P_{i,j} + \\sum_{k\\neq j} P_{i,k} F^{(n-1)}_{k,j} \\leq P_{i,j} + \\sum_{k\\neq j} P_{i,k} x_k  = x_i$  for all $i$  \n",
    "\n",
    "where we have the point-wise bound of \n",
    "$F^{(n-1)}_{k,j} \\leq x_k$   \n",
    "which given by the inductive hypothesis \n",
    "\n",
    "Thus we have \n",
    "\n",
    "$F_{i,j}^{(n)} \\leq x_i$  for all natural numbers $n$.  \n",
    "\n",
    "\n",
    "$F_{i,j}^{(n)}$ is a CDF and hence is monotone non-decreasing and bounded above by 1, but also as shown above, $x_i$.  Hence \n",
    "\n",
    "$\\lim_{n \\to \\infty} F_{i,j}^{(n)} = F_{i,j}^{(\\infty)} $ exists and is equal to $x_i^*$ which is the minimal valued $x_i$ for fixed $i$ of the set of solutions that satisfy  \n",
    "\n",
    "$x_i = P_{i,j} + \\sum_{k\\neq j} P_{i,k} x_k$  for all $i \\geq 0$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Wald's Equation and Renewal Theory\n",
    "\n",
    "** note this isn't actually from Feller but instead from page 422 of Ross's Intro To Probability Models and ties in with some exercises in Gallagher**  \n",
    "\n",
    "consider applying Wald's Equality where \n",
    "\n",
    "$0 \\lt X$  \n",
    "\n",
    "(recall that $X(\\omega)$ is a time denominated increment)  and $X_i$ are iid\n",
    "\n",
    "$\\bar{ X} \\lt \\infty$  \n",
    "\n",
    "and $S_n = X_1 + X_2 +... + X_n$  \n",
    "\n",
    "and with the stopping rule of stopping at the first cumulative arrival time $\\gt t$ \n",
    "\n",
    "**open item: considering doing this for $\\geq t$, the stopping rule is intact... the issue really seems to be notational** \n",
    "\n",
    "that is, we are considering \n",
    "\n",
    "$S_{N(t)+1}$  \n",
    "\n",
    "where $N(t)$ is the number of arrivals at time $t$ \n",
    "\n",
    "$S_{N(t)+1} = t  + Y(t)$  \n",
    "\n",
    "where $Y(t)$ is the excess at time $t$, i..e. the final $X_i$ arrial is partitioned into the amount up to and including $t$ and the amount after -- the latter is what's counted by $Y(t)$. For avoidance of doubt $Y(t)\\geq 0$ \n",
    "\n",
    "taking expectations of both sides, we have \n",
    "\n",
    "\n",
    "$E\\big[S_{N(t)+1}\\big] = E\\big[t  + Y(t)\\big] = E\\big[X_1 + X_2 +... + X_{N(t)} + X_{N(t)+1}\\big]$  \n",
    "\n",
    "$t + E\\big[ Y(t)\\big] = \\bar{X}E\\big[{N(t)+1}\\big] = \\bar{X}E\\big[{N(t)}\\big]+ \\bar{X}$  \n",
    "\n",
    "$E\\big[{N(t)}\\big]+ 1 = \\frac{t}{\\bar{X}} + \\frac{E\\big[ Y(t)\\big]}{\\bar{X}}$  \n",
    "\n",
    "$E\\big[{N(t)}\\big] = \\frac{t}{\\bar{X}} + \\frac{E\\big[ Y(t)\\big]}{\\bar{X}} - 1$  \n",
    "\n",
    "\n",
    "$\\frac{t}{\\bar{X}}  - 1 \\leq E\\big[{N(t)}\\big] = \\frac{t}{\\bar{X}} + \\frac{E\\big[ Y(t)\\big]}{\\bar{X}} - 1 = \\frac{t}{\\bar{X}} - 1 + \\frac{E\\big[ Y(t)\\big]}{\\bar{X}} $  \n",
    "\n",
    "sometimes the notation $m(t) :=  E\\big[{N(t)}\\big]$ is used instead.  This is then re-written as \n",
    "\n",
    "$\\frac{t}{\\bar{X}}  - 1 \\leq m(t) = \\frac{t}{\\bar{X}}  - 1 + \\frac{E\\big[ Y(t)\\big]}{\\bar{X}}$   \n",
    "\n",
    "**some important special cases** \n",
    "\n",
    "*infinite expected waiting time*\n",
    "we know that it may be possible for expected waiting times to be infinite, if the renewal does not have a second moment.  In such a case, by positivity, we can still be assured that the lower bound is valid.  As for the upper bound, we'd re-run the above argument, but on a truncated $\\hat{X}$, and take limits as needed. Carefully pursuing this (as in Ross, Gallagher, or Feller) then recovers the elementary renewal theorem.  \n",
    "- - - -\n",
    "Of more interest for this writeup are caes where $E\\big[ Y(t)\\big]$ is finite *and* we may estimate it or find a useful upper bound for it. This motivates cases of  \n",
    "\n",
    "\n",
    "*monotonocity in a graph *  \n",
    "\n",
    "note: for *many* special cases of interest we may be about to bound $E\\big[ Y(t)\\big]$ \n",
    "\n",
    "In a particular special case of interest -- when there is *monotonicity* in the graph / underlying countable state markov chain, we **know** that any possible renewal from the starting node (call it 0)  must go through all other nodes, which gives a dominance relation of \n",
    "\n",
    "$\\{\\text{time from 0 }  \\to \\text{ k}\\} + \\{\\text{time from k }  \\to \\text{0}\\} = \\{\\text{time from 0 }  \\to \\text{ 0}\\} $  \n",
    "\n",
    "for $k \\gt 0$  \n",
    "\n",
    "\n",
    "over any legal sample path, and for avoidance of doubt, both quantities being time denominated are real non-negative.  \n",
    "\n",
    "taking expectations we have \n",
    "\n",
    "$E\\big[\\text{time from 0 }  \\to \\text{ k} \\big] + E\\big[\\text{time from k}  \\to \\text{ 0}\\big] = E\\big[\\text{time from 0 }  \\to \\text{ 0}\\big] = \\bar{X} $  \n",
    "\n",
    "$E\\big[\\text{time from 0 }  \\to \\text{ k} \\big] \\leq \\bar{X} $  \n",
    "\n",
    "Thus we can write \n",
    "\n",
    "$E\\big[ Y(t)\\big] = \\sum_{k\\gt 0} p_k E\\big[\\text{time from 0 }  \\to \\text{ k} \\big] \\leq \\sum_{k\\gt 0} p_k \\bar{X} = \\bar{X} \\sum_{k\\gt 0} p_k \\leq \\bar{X} $  \n",
    "\n",
    "where $p_k$ denotes the probability of being in state $k$ at the stopping time.  By definition we have \n",
    "\n",
    "$0 \\leq \\sum_{k\\gt 0} p_k \\leq  p_0 + \\sum_{k\\gt 0} p_k = \\sum_{k\\geq 0} p_k  = 1$  \n",
    "\n",
    "- - - - \n",
    "\n",
    "In these cases of monotonicity, we may then say:  \n",
    "\n",
    "\n",
    "$\\frac{t}{\\bar{X}}  - 1 \\leq m(t) = \\frac{t}{\\bar{X}} -1 + \\frac{E\\big[ Y(t)\\big]}{\\bar{X}} \\leq \\frac{t}{\\bar{X}}-1 + \\frac{\\bar{X}}{\\bar{X}}  = \\frac{t}{\\bar{X}} -1 +1 = \\frac{t}{\\bar{X}}$   \n",
    "\n",
    "So we may conclude that \n",
    "\n",
    "$\\frac{t}{\\bar{X}}  - 1 \\leq m(t) \\leq \\frac{t}{\\bar{X}}$    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternating Renewal Theorem:  **  \n",
    "\n",
    "Suppose that we have iid $X_n$ and iid $Y_n$ where $X_n$ denotes \"on\" time and $Y_n$ is off time. Each random variable denotes an arrival time, and they come in sequence -- i.e. first always $X_i$ then $Y_i$ then $X_{i+1}$ then $Y_{i+1}$ then $X_{i+2}$ and so on.  Further suppose that each random variable has a first moment.  \n",
    "\n",
    "Thus $Z_n := X_n + Y_n$  is a renewal process that starts with the system off, 'turns on' with the arrival denoted by $X$ and then turns off again at the $Y$ arrival -- which constitutes a renewal.  \n",
    "\n",
    "An interesting result: \n",
    "\n",
    "$\\lim_{t \\to \\infty} P\\big[\\text{system is \"on\" at time t}\\big]= \\frac{\\bar{X}}{\\bar{X} + \\bar{Y}} = \\frac{E\\big[X_1\\big]}{E\\big[X_1 + Y_1\\big] }$  \n",
    "\n",
    "\n",
    "we suggest two different proofs / ways of deriving this result.  One using the Renewal Equilibrium theorem (variously called Feller-Erdos-Pollards for arithmetic/lattice cases and Blackwell's theorem for non-arithmetic case), and the other approach is to find that the above conforms to the time averaged result -- hence if there is a limmitting distribution / equilibrium for $Z$ then the above relationship must follow.  (As always the time averaged case has an interpretation in terms problems of 'random incidence' for a finite but sufficiently large $t$.)  \n",
    "\n",
    "\n",
    "**1.)** \n",
    "\n",
    "Approach one: using the key limit theorem, we know the CDF of the age (**2x check on residual life**) is given by \n",
    "\n",
    "$\\lim_{t \\to \\infty} Z_{(t)}\\big(z\\big) =\\frac{Pr\\{Z \\gt (z)\\} }{E\\big[Z_1\\big]} = \\frac{Pr\\{Z \\gt (z)\\} }{E\\big[X_1 + Y_1\\big]} = \\frac{Pr\\{Z \\gt (z)\\} }{E\\big[X_1\\big] + E\\big[Y_1\\big]}$  \n",
    "\n",
    "of course if we integrate over $z$ from 0 to $\\infty$ we get a \n",
    "\n",
    "$\\frac{\\int_0^{\\infty} Pr\\{Z \\gt (z)\\}dz }{E\\big[X_1\\big] + E\\big[Y_1\\big]} = \\frac{E\\big[Z_1\\big] }{E\\big[X_1\\big] + E\\big[Y_1\\big]} =1 $\n",
    "\n",
    "which confirms that this is a valid probability distribution.  \n",
    "\n",
    "However, we can further refine this.  For convenience note that \n",
    "\n",
    "$E\\big[\\mathbb I_{Z_i \\gt z}\\big] = E\\big[\\mathbb I_{Z \\gt z}\\big] = Pr\\{Z \\gt (z)\\} $  \n",
    "\n",
    "The indicator on the left can be further decomposed, taking advantage of the sequential ordering of arrivals.  \n",
    "\n",
    "$\\mathbb I_{Z_i \\gt z} = \\mathbb I_{X_i \\gt z} + \\mathbb I_{\\text{convolution :} X\\leq z * Y \\gt (z-x)}$  \n",
    "\n",
    "(i.e. in effect the above recognizes two disoint events $\\{X_i \\gt z\\}$ and $\\{X\\leq z\\}$  and hence their probabilities add... in fact the indicator r.v.'s do as well, over any sample paths)  \n",
    "\n",
    "taking expectations we have \n",
    "\n",
    "$ Pr\\{Z \\gt (z)\\} = E\\big[\\mathbb I_{Z_i \\gt z}\\big] = E\\big[\\mathbb I_{X_i \\gt z}\\big] + E\\big[\\mathbb I_{\\text{convolution :} X\\leq z * Y \\gt (z-x)}\\big] =  Pr\\{X \\gt (z)\\}  + E\\big[\\mathbb I_{\\text{convolution :} X\\leq z * Y \\gt (z-x)}\\big]$  \n",
    "\n",
    "Now if we only wanted the portion of time that is \"on\", that is given directly by $Pr\\{X \\gt (z)\\}$ -- and if integrate over this, we'd have 'summed' over all probabilities of being on in this equilibrium state, which is given below as:  \n",
    "\n",
    "\n",
    "$\\frac{\\int_0^{\\infty} Pr\\{X \\gt (z)\\} dz}{E\\big[X_1\\big] + E\\big[Y_1\\big]} = \\frac{E\\big[X_1\\big] }{E\\big[X_1\\big] + E\\big[Y_1\\big]} = \\frac{\\bar{X}}{\\bar{X} + \\bar{Y}}$  \n",
    "\n",
    "as desired \n",
    "\n",
    "\n",
    "**2.)** \n",
    "\n",
    "Time averaged renewal reward approach: As before, we assume each $X_i$ and $Y_i$ have a first moment. Using **6.3** from Ross & Pekoz we can see that for renewal reward processes \n",
    "\n",
    "$\\lim_{t \\to  \\infty} \\frac{R(t)}{t} =_{as} \\frac{E[R_1]}{E[Z_1]} = \\lim_{t \\to \\infty} \\frac{E[R(t)]}{t}$  \n",
    "\n",
    "where we have a reward of 1 if in the first state, and $Z_i = X_i + Y_i$, hence  \n",
    "\n",
    "$E\\big[Z_1\\big] = E\\big[X_1\\big] + E\\big[Y_1\\big] $    \n",
    "\n",
    "and $R_1 = X_1$ so $E[R_1] = E[X_1]$ \n",
    "\n",
    "giving the desired result that the time averaged probability is \n",
    "$\\frac{\\bar{X}}{\\bar{X} + \\bar{Y}}$  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**problem 10, page 470 of Ross's Intro to Probability Models** \n",
    "\n",
    "suppose a renewal process has mean inter-arrival time of $\\bar{X}$.  Now suppose that each event of this process is independently counted with probability $p \\gt 0$. The counting process is given by $N_C(t)$ for $t\\gt 0$ \n",
    "\n",
    "(a) Is this still a renewal process? Yes.  We still have bonafide iid random variables such that the process gets a fresh start at each renewal.  In this case we may work explicitly with $Z = \\sum_{i=1}^N X_i$ where $N$ is geometrically distributed with probability of success $p$. However for generalization purposes we take a slightly different route.  It is worth noting that $N_C(t) = p\\cdot N(t)$ and hence we have \n",
    "\n",
    "$\\lim_{t \\to \\infty} N_C(t) = \\lim_{t \\to \\infty} p\\cdot N(t)= p \\cdot \\lim_{t \\to \\infty} N(t) = \\infty $\n",
    "\n",
    "because $N(t)$ is a bonafide counting process.  This is combined with iid arrivals enough to verify that we have a valid renewal process.  \n",
    "\n",
    "And the renewal rate for this process, using SLLN is \n",
    "\n",
    "$\\lim_{t \\to \\infty} \\frac{N_C(t)}{t} = \\lim_{t \\to \\infty} \\frac{p\\cdot N(t)}{t}= p \\cdot \\lim_{t \\to \\infty} \\frac{N(t)}{t} = \\frac{p}{\\bar{X}} $\n",
    "\n",
    "we can also interpret this in terms of Blackwells theorem and see that the equilibrium probability of renewal is the same as before but now scaled by $p$ so we have \n",
    "\n",
    "$Pr\\{\\text{renewal in equilibrium}\\} = \\frac{p}{\\bar{X}}$  \n",
    "\n",
    "hence   \n",
    "\n",
    "$\\text{expected renewal time} = \\frac{\\bar{X}}{p}$  \n",
    "\n",
    "\n",
    "another way of getting at this expected renewal time (supposing $\\bar{X} \\lt \\infty$ for clarity)  is to take advantage of independence of $p$ of acceptance the the renewal process, apply total expectation and make use of memorylessness of the geometric acceptance process\n",
    "\n",
    "$\\{\\text{expected renewal time}\\} = \\bar{X} +p \\cdot 0 + (1-p)\\cdot \\{\\text{expected renewal time}\\} = \\bar{X} +p \\cdot 0 + (1-p)\\cdot \\{\\text{expected renewal time}\\}$   \n",
    "\n",
    "$p\\cdot \\{\\text{expected renewal time}\\} = \\bar{X}$   \n",
    "\n",
    "$\\{\\text{expected renewal time}\\} = \\frac{\\bar{X}}{p}$   \n",
    "\n",
    "\n",
    "- - - - \n",
    "\n",
    "\n",
    "*comment:*  for insights, we may first consider the idealized renewal process -- i.e. the Poisson process.   This problem then asks about splitting of Poisson processes with probability $p$ which gives the desired answer that the split process has a renewal rate as before times $p$.  \n",
    "\n",
    "- - - - - \n",
    "**generalization** \n",
    "\n",
    "suppose the probality of acceptance varies over time, but is still *independent* of the arrivals.  \n",
    "\n",
    "*comment:* we may interpret this in the idealized case as inhomogenous renewal process.  The emphasis here is on a simultaneous finite state homogenous markov chain running 'along side' the main renewal process.  Following that structure we'll assume that both processes are integer time with the accompanying markov chain being aperiodic and irreducible.  (We can generalize the result but care is needed to avoid unpleasant special cases -- e.g. a renewal process that only has renewals at irrational times -- perhaps multiples of $\\pi$ and an adjacent probability process that only accepts at rational times (say integers) will be defective. Another approach would be to place a lower bound of some  $\\alpha \\gt 0$ such that $p(t) \\gt \\alpha$ for large enough t.)  Let $p(t)$ tend to a limit such that we have \n",
    "\n",
    "$\\lim_{t \\to \\infty} p(t) = p \\in (0,1)$\n",
    "\n",
    "At this point we can run our previous argument almost verbatim.  \n",
    "\n",
    "in particular, note \n",
    "\n",
    "$\\lim_{t \\to \\infty} N_C(t) = \\lim_{t \\to \\infty} p(t)\\cdot N(t) = \\lim_{t \\to \\infty}p(t) \\cdot \\lim_{t \\to \\infty} N(t) = p \\cdot \\lim_{t \\to \\infty} N(t) = \\infty $  \n",
    "\n",
    "and \n",
    "\n",
    "$\\lim_{t \\to \\infty} \\frac{N_C(t)}{t} = \\lim_{t \\to \\infty} \\frac{p(t) \\cdot N(t)}{t}= \\lim_{t \\to \\infty} p(t) \\cdot \\lim_{t \\to \\infty} \\frac{N(t)}{t} = p \\cdot \\frac{1}{\\bar{X}}= \\frac{p}{\\bar{X}} $\n",
    "\n",
    "and \n",
    "\n",
    "$Pr\\{\\text{renewal in equilibrium}\\} = \\frac{p}{\\bar{X}}$  \n",
    "\n",
    "hence\n",
    "\n",
    "$\\text{expected renewal time} = \\frac{\\bar{X}}{p}$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**This is an adaptation of problem 5.45 in Gallagher** \n",
    "\n",
    "\n",
    "Suppose there are only two ways into node $m$, via node $k$ or $n$.  Suppose the chain is irreducible and positive recurrent.  (Aperiodic is helpful to clean up the argument, though not strictly needed.)  The argument is driven by concerns with problems of runs / streaks, however it works more generally.  Note: outside of a streaks situation, some additional care may be needed in properly computing $\\bar{X}$ and $\\bar{Y}$.   \n",
    "\n",
    "*For simplicity, consider the case that $k\\to m$ occurs with $p_{i,k}=1$  and that $n\\to m$ occurs with $p_{n,k}=1$*.  Various complications and extensions will be considered later.  \n",
    "\n",
    "As before we have the long-term renewal rate at state $m$, via basic markov chain mechanics, is given by \n",
    "\n",
    "$\\frac{1}{\\bar{X}}+\\frac{1}{\\bar{Y}} = \\frac{1}{\\bar{Z}} = \\frac{\\bar{Y}}{\\bar{X}\\bar{Y}}+ \\frac{\\bar{X}}{\\bar{X}\\bar{Y}} = \\frac{\\bar{X} + \\bar{Y}}{\\bar{X}\\bar{Y}}$  \n",
    "\n",
    "hence we know \n",
    "\n",
    "$\\bar{Z} = \\frac{\\bar{X}\\bar{Y}}{\\bar{X} + \\bar{Y}}$  \n",
    "\n",
    "where $\\bar{X}$ is expected time of renewal through $k$ and $\\bar{Y}$ is expected time of renewal through $n$.  These are **not exclusive paths**.  \n",
    "\n",
    "Now we can also compute $\\bar{Z}$ via total expectation, where we insist on considering mutually exclusive paths.  \n",
    "\n",
    "$\\bar{Z} = p\\cdot \\bar{A} + (1-p)\\cdot\\bar{B} = p \\bar{A} + q\\bar{B}$  \n",
    "\n",
    "where $\\bar{A}$ is expected renewal from $m \\to m$ for a path that goes through $k$ and *does NOT visit* $n$   \n",
    "$\\bar{B}$ is expected renewal from $m \\to m$ for a path that goes through $n$ and *does NOT visit* $k$ \n",
    "\n",
    "These are now exclusive sample paths.  And $p$ is the probability of the former happening while $q = 1-p$ is the probability of the latter happening.  Given time homogeneity of transitions, and Markov property, we see that this probability is the same for any renewal beginning and ending at state $m$.  For the analysis that follows it must be the case that $p\\in(0,1)$ as the infinite series, etc. are not meaningful for $p=0$ or $p=1$. **In general this entire argument breaks under degenerate cases where some process (perhaps deterministically, perhaps as a subset of the other) finishes first with $p = 1$.  We can logically think through examples to see this, but the mathematical underpinning is our below geometric series must both converge which requires** $p\\in(0,1)$.   \n",
    "\n",
    "Note that for each renewal at $k$ we have a geometric distribution of time until next arrival that goes through $k$, not $n$ (and vice versa) -- i.e. the number of renewals until \"first success\" is geometrically distributed.  Applying total expectation, this gives us \n",
    "\n",
    "$\\bar{X} = \\sum_{k=0}^\\infty q^k p\\big(k \\bar{B} + \\bar{A}\\big) = \\bar{B}\\big(\\sum_{k=0}^\\infty q^k p\\cdot k \\big) + \\bar{A}\\big(\\sum_{k=0}^\\infty q^k p \\big) = \\bar{B}\\big(\\frac{q}{p}\\big) + \\bar{A}$ \n",
    "\n",
    "$\\bar{Y} = \\sum_{k=0}^\\infty p^k q\\big(k \\bar{A} + \\bar{B}\\big) = \\bar{A}\\big(\\frac{p}{q}\\big) + \\bar{B}$ \n",
    "\n",
    "hence we have \n",
    "\n",
    "$\\bar{A} = \\bar{X} -\\bar{B}\\big(\\frac{q}{p}\\big)$  \n",
    "$\\bar{B} = \\bar{Y} - \\bar{A}\\big(\\frac{p}{q}\\big) $  \n",
    "\n",
    "thus  \n",
    "\n",
    "$\\bar{Z} =  p \\bar{A} + q\\bar{B} = p \\Big(\\bar{X} -\\bar{B}\\big(\\frac{q}{p}\\big)\\Big) + q\\Big(\\bar{Y} - \\bar{A}\\big(\\frac{p}{q}\\big)\\Big) = p \\bar{X} + q\\bar{Y} - \\big(q\\bar{B} + p\\bar{A}\\big) = p \\bar{X} + q\\bar{Y} -  \\bar{Z}$  \n",
    "\n",
    "$2\\bar{Z} = p \\bar{X} + q\\bar{Y}$  \n",
    "\n",
    "$\\bar{Z} = \\frac{1}{2}\\big(p \\bar{X} + q\\bar{Y}\\big)$  \n",
    "\n",
    "combining with the above, we have \n",
    "\n",
    "$ \\frac{\\bar{X}\\bar{Y}}{\\bar{X} + \\bar{Y}} = \\bar{Z} = \\frac{1}{2}\\big(p \\bar{X} + q\\bar{Y}\\big)$  \n",
    "\n",
    "thus \n",
    "\n",
    "$\\big(p \\bar{X} + q\\bar{Y}\\big)=2\\frac{\\bar{X}\\bar{Y}}{\\bar{X} + \\bar{Y}}$  \n",
    "\n",
    "we also know that p and q sum to one.  In matrix form this gives us \n",
    "\n",
    "$\\mathbf {Mv}= \\left[\\begin{matrix}\\bar{X} & \\bar{Y}\\\\1 & 1\\end{matrix}\\right]\\left[\\begin{matrix}p\\\\q\\end{matrix}\\right]\n",
    " =\\left[\\begin{matrix}\\frac{2 \\bar{X} \\bar{Y}}{\\bar{X} + \\bar{Y}}\\\\1\\end{matrix}\\right] = \\mathbf c$  \n",
    " \n",
    "in the case that $\\bar{X} \\neq \\bar{Y}$, $\\mathbf M$ is invertible and we have \n",
    "\n",
    "$\\left[\\begin{matrix}p\\\\q\\end{matrix}\\right] = \\mathbf M^{-1}\\mathbf c = \\left[\\begin{matrix}\\frac{\\bar{Y}}{\\bar{X} + \\bar{Y}}\\\\\\frac{\\bar{X}}{\\bar{X} + \\bar{Y}}\\end{matrix}\\right]\n",
    "$\n",
    "- - - \n",
    "**begin detour on singular case**  \n",
    "the special case of $\\bar{X} \\neq \\bar{Y}$ would seem to require some additional consideration in this case as any $p\\in(0,1)$ would satisfy.  We could approach this via a continuity based argument i.e. the exact solution above must hold even in the singular case due to continuity property of probabilities.  However a more direct approach would be to go back to our equations:  \n",
    "\n",
    "$(i)  \\bar{A} = \\bar{X} -\\bar{B}\\Big(\\frac{q}{p}\\Big)$  \n",
    "$(ii)  \\bar{B} = \\bar{Y} - \\bar{A}\\Big(\\frac{p}{q}\\Big)$  \n",
    "\n",
    "and in the special case of $\\bar{X} =\\bar{Y}$ we have  \n",
    "\n",
    "$\\bar{B} = \\bar{X} - \\bar{A}\\big(\\frac{p}{q}\\big)$  \n",
    "\n",
    "subsituting in to (i), we have \n",
    "\n",
    "$\\bar{A} = \\bar{X} - \\Big(\\bar{X} - \\bar{A}\\big(\\frac{p}{q}\\big)\\Big)\\Big(\\frac{q}{p}\\Big) =\\bar{X} - \\frac{q}{p}\\bar{X} +\\bar{A}$  \n",
    "\n",
    "subtracting $\\bar{A}$ from each side tells us \n",
    "\n",
    "$\\bar{X} - \\frac{q}{p}\\bar{X} = \\big(1 - \\frac{q}{p}\\big)\\bar{X}=0$  \n",
    "\n",
    "thus if $p\\neq q$ then it must be the case that $\\bar{X} = 0$ (and $\\bar{Y} = \\bar{X} = 0$) but this contradicts the fact that all renewal times at $m$ through states $k$ and $n$ are strictly positive and hence any expected renewal time is strictly positive. (The argument still holds under more nuanced conditions -- the arrival times are non-negative and $Pr\\{X\\gt 0\\} \\gt 0$ with discrete time intervals, so summing over that complementary CDF means a positive expected value).  \n",
    "\n",
    "Hence we see that $\\bar{X} = \\bar{Y}$ implies $p = q$, or equivalently   \n",
    "\n",
    "$\\bar{X} = \\bar{Y}$ has the single unique solution given by   \n",
    "$\\left[\\begin{matrix}p\\\\q\\end{matrix}\\right] = \\left[\\begin{matrix}\\frac{\\bar{Y}}{\\bar{X} + \\bar{Y}}\\\\\\frac{\\bar{X}}{\\bar{X} + \\bar{Y}}\\end{matrix}\\right] = \\left[\\begin{matrix}\\frac{1}{2}\\\\\\frac{1}{2}\\end{matrix}\\right]$  \n",
    "\n",
    "**end detour on singular case**    \n",
    "- - - - \n",
    "**alternative derivation: renewal rewards and Bayes**  \n",
    "Sketch of Renewal Reward argument:  \n",
    "\n",
    "based on the beginning, we have  \n",
    "$\\frac{1}{\\bar{X}}+\\frac{1}{\\bar{Y}} = \\frac{1}{\\bar{Z}} = \\frac{\\bar{Y}}{\\bar{X}\\bar{Y}}+ \\frac{\\bar{X}}{\\bar{X}\\bar{Y}} = \\frac{\\bar{X} + \\bar{Y}}{\\bar{X}\\bar{Y}}$  \n",
    "\n",
    "which implies  \n",
    "$\\bar{Z} = \\frac{\\bar{X}\\bar{Y}}{\\bar{X} + \\bar{Y}}$  \n",
    "\n",
    "\n",
    "hence the long-run portion of rewards from arrivals via $k$ is \n",
    "\n",
    "$p = \\frac{\\frac{1}{\\bar{X}}}{\\frac{1}{\\bar{Z}}} = \\frac{1}{\\bar{X}}\\big({\\frac{1}{\\bar{Z}}}\\big)^{-1} = \\frac{1}{\\bar{X}}\\Big(\\frac{\\bar{X}\\bar{Y}}{\\bar{X} + \\bar{Y}}\\Big) = \\frac{\\bar{Y}}{\\bar{X} + \\bar{Y}}$    \n",
    "\n",
    "This is the intuition behind the above formula. with $\\lambda_x = \\frac{1}{\\bar{X}}$ it should *exactly* remind us of the situation with combined Poisson Processes.  We can justify it exactly via Bayes and the key limit theorem.  \n",
    "- - - - \n",
    "Now Bayes Rule /conditional probability tells us \n",
    "\n",
    "$P\\big(A_1, A_2 \\big) = P\\big(A_1\\big) P\\big(A_2\\big \\vert A_1\\big) = P\\big(A_2\\big) P\\big(A_1\\big \\vert A_2\\big) $    \n",
    "\n",
    "$ P\\big(A_2\\big \\vert A_1\\big) = \\frac{P\\big(A_2\\big) P\\big(A_1\\big \\vert A_2\\big)}{P\\big(A_1\\big)}$    \n",
    "let $A_1$ be the event the we've arrived in state $m$ on the rth trial, and $A_2$ be the event that we were in state $k$ in trial $r-1$  \n",
    "(as a technical nit, we may insist on $r$ large enough such that $P\\big(A_1, A_2 \\big) \\gt 0$)  \n",
    "\n",
    "- - - -  \n",
    "as a reminder: time homgenous markov chains, where only the above two nodes feed into $m$, must obey \n",
    "\n",
    "$u_m^{(r)} = u_k^{(r-1)}\\cdot p_{k,m} + u_n^{(r-1)}\\cdot p_{n,m} $  \n",
    "\n",
    "so combining Markov property with Bayes rule gives:  \n",
    " \n",
    "$ P\\big(A_2\\big \\vert A_1\\big) = \\frac{P\\big(A_2\\big)\\cdot P\\big(A_1\\big \\vert A_2\\big)}{P\\big(A_1\\big)} = \\frac{u_k^{(r-1)}\\cdot p_{k,m} }{u_m^{(r)}}$    \n",
    "\n",
    "passing limits   \n",
    "$\\lim_{r \\to \\infty} P\\big(A_2\\big \\vert A_1\\big) = \\lim_{r \\to \\infty} \\frac{u_k^{(r-1)}\\cdot p_{k,m} }{u_m^{(r)}} =  \\frac{\\pi_k\\cdot p_{k,m} }{\\pi_m}$    \n",
    "\n",
    "and in the above fully worked problem, we have $p_{k,m} = 1$, so \n",
    "\n",
    "$\\lim_{r \\to \\infty} P\\big(A_2\\big \\vert A_1\\big) =  \\frac{\\pi_k }{\\pi_m} = \\frac{\\frac{1}{\\bar{X}} }{\\frac{1}{\\bar{Z}}}= \\frac{\\bar{Y}}{\\bar{X} + \\bar{Y}}$    \n",
    "\n",
    "However, since we have the strong Markov Property, the process renews each time $A_1$ occurs, and hence the limitting values must reflect those in the short run as well, and the above probability holds in general.  \n",
    "- - - - -  \n",
    "There is considerable appeal to deriving the result via Bayes and a key limit theorem.  **However, as is, this particular argument seems incomplete**.  \n",
    "\n",
    "The underlying idea is that if the absorbtion probabilities don't hold in the limit, then they don't hold for individual cycles.  The approach here seems to be biased in favor of shorter sample paths vs longer ones (think inspection paradox which weights long ones more than shorter).   The more careful approach of looking at markov chain implications for steady state rates, and then a geometric series computation for expected time over disjoint paths, is currently preferable.  \n",
    "\n",
    "We may also consider noting that the above is equivalent to  \n",
    "$\\lim_{r \\to \\infty} \\frac{N_{\\text{through k}}(r)}{N(r))} = \\lim_{r \\to \\infty} \\frac{\\frac{r}{\\bar{X}}}{\\frac{r}{\\bar{Z}}}$    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**follow-up: not just the limitting value-- I want to show that residual life in general must be greater than the expected renewal rate... some inequalities on this are in 2 of Ross's texts** \n",
    "\n",
    "\n",
    "maybe set this up as a point-wise bound using Indicator random variables... \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**another look at the theory of runs**   \n",
    "(basically ideas from Feller augmented / belabored with some ideas of my own\n",
    "\n",
    "You have the solution via first step analysis.\n",
    "\n",
    "I'll point out that there is an interesting insight to be had via last-step analysis.  First consider an easier problem of just estimating expected time until a run of $r$ heads. \n",
    "\n",
    "So, for the expected time up until a run of $r$ heads in a row: we can create a random variable $X$ to take on probabilities of a first run of $r $ heads at time $t$.  Similarly, ignore runs of heads and just consider having $Y$ be the random variable that gives time up until $s$ heads in a row. These are both positive integer valued random variables with minimum values of $r$ and $s$ of course.  The simplification is that will consider these as separate and unrelated problems. \n",
    "\n",
    "\n",
    "Let's tackle the run of heads case.  There is some probability $u_i$ of a run of r heads aka a success (aka a renewal) occurring at the ith turn in the trial.  After such a success we would run the experiment again and have a fresh start, looking for the next run of r heads, and log the results for $i + 1, i+2$, and so on.  And we keep on doing this on and on.  (Note: that these $u_i$ associated with our repeated process and in fact $\\sum_i u_i = \\infty$ so they are not part of a probability distribution)\n",
    "\n",
    "Now suppose it is time $n$ and we condition on having just observed $r$ heads in a row which occurs with probability $p^r$.  (In terms of avoiding pathologies, we know that this result eventually occurs almost surely-- why? geometric series argument).  Now apply last step analysis\n",
    "\n",
    "Let $A_{j}^{(k)}$ denote the event that a success (renewal) occurred at time $j$ and then $k$ heads were tossed afterward over the next $k$ tosses that must have followed.  So we have\n",
    "\n",
    "$Pr\\{A_{n}^{(0)} \\bigcup A_{n-1}^{(1)} \\bigcup A_{n-2}^{(2)} \\bigcup ... \\bigcup A_{n-(r-1)}^{(r-1)}\\} \\leq Pr\\{A_{n}^{(0)}\\} +  Pr\\{A_{n-1}^{(1)}\\} +  Pr\\{A_{n-2}^{(2)}\\} + ... + +  Pr\\{ A_{n-(r-1)}^{(r-1)} \\}$  \n",
    "$= 1 \\cdot u_{n} + p^{1} \\cdot u_{n-1} +  p^{2}\\cdot u_{n-2} + ... + p^{r-1}\\cdot u_{n-(r-1)}$\n",
    "\n",
    "by Boole's Inequality (aka Union Bound).  But the events on are mutually exclusive (e.g. if $r=5$  and $n=14$ we have one and only one success between times $\\{10, 11, 12, 13, 14\\}$ for any possible sample path) hence they are additive and we have the equality case here.  This partitions all possible events in the sample space associated with having noticed at time $n$ that the last $r$ tosses were heads.  So\n",
    "\n",
    "$Pr\\{A_{n}^{(0)} \\bigcup A_{n-1}^{(1)} \\bigcup A_{n-2}^{(2)} \\bigcup... \\bigcup A_{n-(r-1)}^{(r-1)}\\} = 1 \\cdot u_{n} + p^{1} \\cdot u_{n-1} +  p^{2}\\cdot u_{n-2} + ... + p^{r-1}\\cdot u_{n-(r-1)}$\n",
    "\n",
    "But we are conditioning on seeing $r$ heads in a row, so we have with probability one  \n",
    "$1 = \\big(1 \\cdot u_{n} + p^{1} \\cdot u_{n-1} +  p^{2}\\cdot u_{n-2} + ... + p^{r-1}\\cdot u_{n-(r-1)}\\big)\\frac{1}{p^r}$\n",
    "\n",
    "what renewal theory tells us is that there is a limiting equilibrium probability of success (renewal) at each point in time for a process like this.  (There are some technical nits about periodicity in particular that I'm ignoring as they don't apply here. In particular this renewal process can be modlled via a finite state markov chain that is irreducible, by inspection -- the chain is aperiodic though if we wanted to take extra care we could make this into a lazy walk or something quite closer, or create a dummy state with a self loop to have renewals flow through, etc -- these remedies would not change probability of hitting x vs y first, though they would modify the renewal rates somewhat.  In any case perioidicity is a nuisance, but a minor one that we may deal with.)  So if we pass a limit with respect to $n$ we get\n",
    "\n",
    "$1 = \\lim_{n \\to \\infty} \\big(p^{0} u_{n} + p^{1} u_{n-1} +  p^{2} u_{n-2} + ... + p^{r-1} u_{n-(r-1)}\\big)\\frac{1}{p^r}$  \n",
    "$= \\big(p^{0} \\frac{1}{\\mathbb E[X] }+ p^{1} \\frac{1}{\\mathbb E[X] } +  p^{2} \\frac{1}{\\mathbb E[X] } + ... + p^{r-1} \\frac{1}\n",
    "{\\mathbb E[X] }\\big) \\frac{1}{p^r} =\\big(p^{0} + p^{1} +  p^{2}  + ... + p^{r-1}\\big) \\frac{1}{\\mathbb E[X] }\\frac{1}{p^r} $   \n",
    "$=\\big(\\frac{1-p^r}{(1-p)}\\big)\\frac{1}{\\mathbb E[X] }\\frac{1}{p^r} $  \n",
    "\n",
    "\n",
    "\n",
    "simplifying, we get \n",
    "$\\mathbb E[X] = \\frac{1-p^r}{(1-p)p^r}= \\frac{1-p^r}{q \\cdot p^r}$ \n",
    "\n",
    "now if we apply the exact same argument for the all tails run we get\n",
    "$\\mathbb E[Y] = \\frac{1-q^s}{p \\cdot q^s}$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** see Probability/theory_of_runs_python.ipynb** \n",
    "\n",
    "Which generalized the above to cases where the streaks are not disjoint.  The idea is qualitatively quite similar, however the individual calculations are tedious and error prone in my experience.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On infinite renewals for non-defective renewal processes  \n",
    "\n",
    "see: my notes under problem 2.28 in chp2 notes to Gallagher's Stochastic Processes \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**comment:**  The problem's result is ultimately clear.  However it feels almost like a trick amongst identities of Generating Functions.  The problem is contained in the 'answers' section in the back, though it took your author a considerable amount of time to parse said answer and recover the missing steps to make things coherent.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Results:**   \n",
    "\n",
    "$U(s) = \\frac{1}{1 - F(s)} = \\sum_{k=0}^\\infty u_k s^k$  \n",
    "this is (3.2) on page 311\n",
    "\n",
    "recall per page 308, that $\\{u_k\\}$ are the probability of there being renewal at $k$ -- for non-transient setups, this sums to $\\infty$ so cannot be a probability.  but the series converges for $\\vert s\\vert \\lt 1$ (recall chapter XI).  \n",
    "\n",
    "The answers in the back note follwing identities\n",
    "\n",
    "(a) $1-F(s) = (1-s) Q(s)$ (to be used first)   \n",
    "(b)$\\bar{X} - Q(s) = (1-s)R(s)$ (to be used a bit later)    \n",
    "\n",
    "(note I chose to use $\\bar{X}$ not $\\mu$ here to avoid visual confusiton with the $u_k$'s)  \n",
    "\n",
    "**Goal: **\n",
    "\n",
    "assuming we have a second moment, show \n",
    "\n",
    "(1.) $\\sum_{k=0}^\\infty \\big(u_k - \\frac{1}{\\bar{X}}\\big)s^k = \\frac{R(s)}{\\bar{X}Q(s)}$  \n",
    "\n",
    "for any $s \\in (0,1)$ \n",
    "\n",
    "(2.) then show it in fact holds for $s:=1$ as well, with no convergence issues.  and at s = 1 \n",
    "(or as I prefer, taking the limit as $s$ approach $1$ from the left)  \n",
    "\n",
    "\n",
    "$\\sum_{k=0}^\\infty \\big(u_k - \\frac{1}{\\bar{X}}\\big)= \\frac{\\sigma^2 - \\bar{X} + \\bar{X}^2}{2 \\bar{X}^2}$ $= \\frac{E\\big[X^2\\big] - \\bar{X}}{2\\bar{X}^2}$  \n",
    "\n",
    "note: the above is interpretted as the total lifetime difference between the probability of a renewal at a particular time, and the steady state probability of renewal at that time \n",
    "\n",
    "**Proof:**  \n",
    "\n",
    "Starting with (1.), we build the relation we want starting with $s\\in(0,1)$ where we have absolute convergence \n",
    "\n",
    "$\\sum_{k=0}^\\infty \\big(u_k - \\frac{1}{\\bar{X}}\\big)s^k = \\big(\\sum_{k=0}^\\infty u_k s^k\\big) -  \\big(\\sum_{k=0}^\\infty \\bar{X}^{-1}s^k \\big) = \\big(U(s)\\big) -\\big(\\frac{\\bar{X}^{-1}}{1-s} \\big) = \\big(\\frac{1}{1 - F(s)}\\big) -\\frac{\\bar{X}^{-1}}{1-s} = \\frac{1}{(1-s) Q(s)} -\\frac{1}{(1-s)\\bar{X}}$ \n",
    "\n",
    "where we used identity (a) on the Right Hand Side \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sum_{k=0}^\\infty \\big(u_k - \\frac{1}{\\mu}\\big)s^k = \\frac{1}{(1-s) Q(s)} -\\frac{1}{(1-s)\\bar{X}} = \\frac{\\bar{X}}{(1-s) \\bar{X}Q(s)} -\\frac{Q(s)}{(1-s)\\bar{X}Q(s)}= \\frac{\\bar{X} - Q(s)}{(1-s)\\bar{X}Q(s)} = \\frac{(1-s)R(s)}{(1-s)\\bar{X}Q(s)}= \\frac{R(s)}{\\bar{X}Q(s)}$ \n",
    "\n",
    "where we used identity (b), on the Right hand side, and 'divided out' $(1-s)$, an operation which is valid for any $s \\neq 1$  \n",
    "\n",
    "(Note: official solution uses this reduced form to make claims directly about the LHS and RHS at $s =1$... the legacy of the $(1-s)$ that *was* there in my derivation makes me a touch concerned, and instead I prefer to show the relation is true for $1 - \\delta$ small positive $\\delta$.  There might be a slightly simpler or more clean approach to get to these results. As a related point, I have lingering concerns about how I explicitly split the geometric series above -- this is fine as we have absolute convergence for $s = 1 - \\delta$, but techincally that intermediate step doesn't stand on its own if we re-examine it at $s=1$.)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This completes part (1.)\n",
    "\n",
    "\n",
    "- - - -\n",
    "part (2.)  \n",
    "\n",
    "we recall that $Q(1) = \\bar{X}$  (i.e. summing / integrating over the complementary CDF) thus we also know \n",
    "\n",
    "$\\lim_{s \\to 1^{-}}Q(s) = Q(1) = \\bar{X}$  \n",
    "\n",
    "(i.e. approach one as a limit from the left)  \n",
    "\n",
    "and we also recall that \n",
    "\n",
    "$R(1) = \\frac{\\sigma^2 - \\bar{X} + \\bar{X}^2}{2} = \\frac{E\\big[X^2\\big] - \\bar{X}}{2}$   \n",
    "\n",
    "since we have a second moment by assumption, this exists and is finite \n",
    "\n",
    "thus\n",
    "\n",
    "$\\lim_{s \\to 1^{-}}R(s) = \\frac{\\sigma^2 - \\bar{X} + \\bar{X}^2}{2} = \\frac{E\\big[X^2\\big] - \\bar{X}}{2}$  \n",
    "\n",
    "This is discussed and shown in multiple ways in my Absorbing State Markov Chains writeup.  It is also discussed and shown directly on page 266 (i.e. beginning of XI, discussing generating functions).  \n",
    "\n",
    "Finally \n",
    "\n",
    "$\\lim_{s \\to 1^{-}} \\sum_{k=0}^\\infty \\big(u_k - \\frac{1}{\\mu}\\big)s^k =  \\lim_{s \\to 1^{-}}\\frac{R(s)}{\\bar{X}Q(s)} =  \\frac{\\sigma^2 - \\bar{X} + \\bar{X}^2}{2\\bar{X}^2} =  \\frac{E[X^2] - \\bar{X}}{2\\bar{X}^2}$   \n",
    "\n",
    "note: the book makes a slightly stronger claim at the end and states\n",
    "\n",
    "$\\sum_{k=0}^\\infty \\big(u_k - \\frac{1}{\\mu}\\big) = RHS$  \n",
    "\n",
    "i.e. it directly evaluates the LHS at $s=1$.  There are some analytic subtleties in the problem and how I approached it that I don't think I fully grasp, hence I am content to evaluate instead approaching the limit from the left.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
